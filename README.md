## The aim of this project is to develop an open-source text-to-video model and create an easy-to-use interface for artists.

### Dataset Preparation
https://github.com/microsoft/XPretrain/tree/main/hd-vila-100m (HD-VILA-100M Dataset) <br />
http://toflow.csail.mit.edu/ (Vimeo-90k Dataset) <br /> 
https://github.com/m-bain/webvid <br />
https://github.com/ExponentialML/Video-BLIP2-Preprocessor <br />
https://github.com/Breakthrough/PySceneDetect <br />

### Finetuning
https://github.com/guoyww/animatediff <br />
https://github.com/showlab/Tune-A-Video <br />
https://github.com/ExponentialML/Text-To-Video-Finetuning <br />
https://www.modelscope.cn/models/damo/text-to-video-synthesis <br />

### Management Framework
https://github.com/spring-projects/spring-framework

### Management UI
https://github.com/gradio-app/gradio

### Management Database
https://github.com/mongodb/mongo

### Demo UI
https://github.com/angular/angular

### Demo Test
https://colab.research.google.com/ <br />
https://github.com/jupyter/notebook <br />
